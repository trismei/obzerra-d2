Build Obzerra MVP â€” Dark Gradient Fraud Detection System

System Purpose: Local-first fraud detection MVP for Philippine insurance claims officers. Must be intuitive, simple, and follow our capstone methodology.

ğŸ¯ MVP Core Features (Phase 1 only)
1. Landing Dashboard

Dark UI with blueâ€“purple gradient header.

Two big CTAs:

â• Check Single Claim

ğŸ“‚ Upload Batch CSV

KPI cards:

Total claims analyzed

% High-risk

Average runtime

Plotly chart: Risk band distribution (Low/Medium/High).

2. Batch CSV Analysis

Upload area: drag & drop / click.

Preview step: show first 20 rows from uploaded file.

Column Mapping step:

User maps their columns to internal keys:

Required: claim_id (or any identifier), total_claim_amount, incident_hour_of_the_day

Optional: policy_number, incident_date, incident_type, incident_severity, witnesses, property_damage, police_report_available, fraud_reported (optional, only for metrics).

Allow â€œNot providedâ€ for optional fields.

Run Analysis â†’ Output:

KPI cards (total rows, % high-risk, runtime).

Results Table: must use actual identifiers from uploaded CSV (not dummy IDs). Columns:

claim_id or mapped ID

risk_score (0â€“100, banded Low/Med/High)

label_pred (fraud/no fraud if thresholded)

Top 2 plain-language reasons

Rules triggered (badges)

Filters: by risk band.

Export: Download Results CSV (original columns + engineered flags + risk_score + reasons).

3. Single Claim Check

Input Form:

Policy #

Claim Amount

Incident Date (picker)

Incident Hour (slider 0â€“23)

Witnesses (#)

Property Damage (Y/N)

Police Report (Y/N)

Incident Type, Incident Severity (dropdowns)

Check Claim â†’ Result Card:

Risk Score (0â€“100) + badge (Low/Med/High).

â€œWhy this resultâ€ (plain sentences, no ML jargon).

Rules triggered (badges: Odd Hour, Amount Anomaly, etc.).

Suggested Next Step (Approve / Verify / Escalate).

Export button: Save as CSV (one row with inputs + outputs).

4. Recent Runs / Export Logs

List of previous batch runs (timestamp, #rows, % high-risk).

Download link for each exported CSV.

ğŸ§© Methodology (follow capstone)

Preprocessing: clean, impute (median/most frequent), normality check.

Features: temporal (hour, weekend), stats (IQR, z-score if normal), Benford flag, rule flags.

Models: Logistic Regression + Random Forest, balanced with SMOTE.

Ensemble: average both â†’ risk_score (0â€“100).

Explainability: Use SHAP internally but always output plain-language reasons in UI (â€œWhy this resultâ€).

ğŸ¨ UI Style

Dark UI + gradient header.

Glassy cards, rounded corners, soft shadows.

Plotly dark mode charts.

Clear CTAs and badges.

Tooltips on inputs (e.g., â€œHour = 0â€“23â€).

Taglish-friendly copy for hints if needed.

âœ… MVP Acceptance Criteria

 App runs locally with Python (Dash, pandas, sklearn, shap, imbalanced-learn, plotly).

 Can train on insurance_claims_featured.csv and save models (lr.pkl, rf.pkl, preprocessor.pkl).

 Batch flow works: upload CSV â†’ map columns â†’ analysis â†’ export with original IDs preserved.

 Single claim flow works: input form â†’ risk score + reasons â†’ export single row.

 Dashboard shows KPIs + risk distribution chart.

 All outputs in plain language, no ML jargon.

 Handles up to ~10k rows in <30s on a laptop.